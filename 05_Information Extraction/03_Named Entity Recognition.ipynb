{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a NER System\n",
    "\n",
    "A simple approach to building an NER system is to maintain a large collection of person/organization/location names that are the most relevant to our company (e.g., names of all clients, cities in their addresses, etc.); this is typically referred to as a gazetteer.\n",
    "\n",
    "Rule-based NER, which can be based on a compiled list of patterns based on word tokens and POS tags.\n",
    "\n",
    "Train an ML model, which can predict the named entities in unseen text.\n",
    "- Normal classifier: classify text word by word\n",
    "- Sequence classifier: looking at the context in which it's being used. (For NER models)\n",
    "\n",
    "Conditional Random Fields (CRFs), one of the popular sequence classifier training algorithms.\n",
    "\n",
    "Typical training data for NER follow BIO notation:\n",
    "- B indicates the beginning of an entity\n",
    "- I inside an entity, indicates when entities comprise more than one word\n",
    "- O other, indicates non-entities.\n",
    "\n",
    "Example: 'Peter' gets tagged as a B-PER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Yasir Abdur\n",
      "[nltk_data]     Rohman\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.tag import pos_tag\n",
    "from sklearn_crfsuite import CRF, metrics\n",
    "from sklearn.metrics import make_scorer,confusion_matrix\n",
    "from pprint import pprint\n",
    "from sklearn.metrics import f1_score,classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "\"\"\"\n",
    "Load the training/testing data. \n",
    "input: conll format data, but with only 2 tab separated colums - words and NEtags.\n",
    "output: A list where each item is 2 lists.  sentence as a list of tokens, NER tags as a list for each token.\n",
    "\"\"\"\n",
    "def load__data_conll(file_path):\n",
    "    myoutput,words,tags = [],[],[]\n",
    "    fh = open(file_path)\n",
    "    for line in fh:\n",
    "        line = line.strip()\n",
    "        if \"\\t\" not in line:\n",
    "            #Sentence ended.\n",
    "            myoutput.append([words,tags])\n",
    "            words,tags = [],[]\n",
    "        else:\n",
    "            word, tag = line.split(\"\\t\")\n",
    "            words.append(word)\n",
    "            tags.append(tag)\n",
    "    fh.close()\n",
    "    return myoutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Get features for all words in the sentence\n",
    "Features:\n",
    "- word context: a window of 2 words on either side of the current word, and current word.\n",
    "- POS context: a window of 2 POS tags on either side of the current word, and current tag. \n",
    "input: sentence as a list of tokens.\n",
    "output: list of dictionaries. each dict represents features for that word.\n",
    "\"\"\"\n",
    "def sent2feats(sentence):\n",
    "    feats = []\n",
    "    sen_tags = pos_tag(sentence) #This format is specific to this POS tagger!\n",
    "    for i in range(0,len(sentence)):\n",
    "        word = sentence[i]\n",
    "        wordfeats = {}\n",
    "       #word features: word, prev 2 words, next 2 words in the sentence.\n",
    "        wordfeats['word'] = word\n",
    "        if i == 0:\n",
    "            wordfeats[\"prevWord\"] = wordfeats[\"prevSecondWord\"] = \"<S>\"\n",
    "        elif i==1:\n",
    "            wordfeats[\"prevWord\"] = sentence[0]\n",
    "            wordfeats[\"prevSecondWord\"] = \"</S>\"\n",
    "        else:\n",
    "            wordfeats[\"prevWord\"] = sentence[i-1]\n",
    "            wordfeats[\"prevSecondWord\"] = sentence[i-2]\n",
    "        #next two words as features\n",
    "        if i == len(sentence)-2:\n",
    "            wordfeats[\"nextWord\"] = sentence[i+1]\n",
    "            wordfeats[\"nextNextWord\"] = \"</S>\"\n",
    "        elif i==len(sentence)-1:\n",
    "            wordfeats[\"nextWord\"] = \"</S>\"\n",
    "            wordfeats[\"nextNextWord\"] = \"</S>\"\n",
    "        else:\n",
    "            wordfeats[\"nextWord\"] = sentence[i+1]\n",
    "            wordfeats[\"nextNextWord\"] = sentence[i+2]\n",
    "        \n",
    "        #POS tag features: current tag, previous and next 2 tags.\n",
    "        wordfeats['tag'] = sen_tags[i][1]\n",
    "        if i == 0:\n",
    "            wordfeats[\"prevTag\"] = wordfeats[\"prevSecondTag\"] = \"<S>\"\n",
    "        elif i == 1:\n",
    "            wordfeats[\"prevTag\"] = sen_tags[0][1]\n",
    "            wordfeats[\"prevSecondTag\"] = \"</S>\"\n",
    "        else:\n",
    "            wordfeats[\"prevTag\"] = sen_tags[i - 1][1]\n",
    "\n",
    "            wordfeats[\"prevSecondTag\"] = sen_tags[i - 2][1]\n",
    "            # next two words as features\n",
    "        if i == len(sentence) - 2:\n",
    "            wordfeats[\"nextTag\"] = sen_tags[i + 1][1]\n",
    "            wordfeats[\"nextNextTag\"] = \"</S>\"\n",
    "        elif i == len(sentence) - 1:\n",
    "            wordfeats[\"nextTag\"] = \"</S>\"\n",
    "            wordfeats[\"nextNextTag\"] = \"</S>\"\n",
    "        else:\n",
    "            wordfeats[\"nextTag\"] = sen_tags[i + 1][1]\n",
    "            wordfeats[\"nextNextTag\"] = sen_tags[i + 2][1]\n",
    "        #That is it! You can add whatever you want!\n",
    "        feats.append(wordfeats)\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting features\n",
    "#Extract features from the conll data, after loading it.\n",
    "def get_feats_conll(conll_data):\n",
    "    feats = []\n",
    "    labels = []\n",
    "    for sentence in conll_data:\n",
    "        feats.append(sent2feats(sentence[0]))\n",
    "        labels.append(sentence[1])\n",
    "    return feats, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a model\n",
    "#Train a sequence model\n",
    "def train_seq(X_train,Y_train,X_dev,Y_dev):\n",
    "   # crf = CRF(algorithm='lbfgs', c1=0.1, c2=0.1, max_iterations=50, all_possible_states=True)\n",
    "    crf = CRF(algorithm='lbfgs', c1=0.1, c2=10, max_iterations=50)#, all_possible_states=True)\n",
    "    #Just to fit on training data\n",
    "    crf.fit(X_train, Y_train)\n",
    "    labels = list(crf.classes_)\n",
    "    #testing:\n",
    "    y_pred = crf.predict(X_dev)\n",
    "    sorted_labels = sorted(labels, key=lambda name: (name[1:], name[0]))\n",
    "    print(metrics.flat_f1_score(Y_dev, y_pred,average='weighted', labels=labels))\n",
    "    print(metrics.flat_classification_report(Y_dev, y_pred, labels=sorted_labels, digits=3))\n",
    "    #print(metrics.sequence_accuracy_score(Y_dev, y_pred))\n",
    "    get_confusion_matrix(Y_dev, y_pred,labels=sorted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cm(cm, labels):\n",
    "    print(\"\\n\")\n",
    "    \"\"\"pretty print for confusion matrixes\"\"\"\n",
    "    columnwidth = max([len(x) for x in labels] + [5])  # 5 is value length\n",
    "    empty_cell = \" \" * columnwidth\n",
    "    # Print header\n",
    "    print(\"    \" + empty_cell, end=\" \")\n",
    "    for label in labels:\n",
    "        print(\"%{0}s\".format(columnwidth) % label, end=\" \")\n",
    "    print()\n",
    "    # Print rows\n",
    "    for i, label1 in enumerate(labels):\n",
    "        print(\"    %{0}s\".format(columnwidth) % label1, end=\" \")\n",
    "        sum = 0\n",
    "        for j in range(len(labels)):\n",
    "            cell = \"%{0}.0f\".format(columnwidth) % cm[i, j]\n",
    "            sum =  sum + int(cell)\n",
    "            print(cell, end=\" \")\n",
    "        print(sum) #Prints the total number of instances per cat at the end.\n",
    "        \n",
    "#python-crfsuite does not have a confusion matrix function, \n",
    "#so writing it using sklearn's confusion matrix and print_cm from github\n",
    "def get_confusion_matrix(y_true,y_pred,labels):\n",
    "    trues,preds = [], []\n",
    "    for yseq_true, yseq_pred in zip(y_true, y_pred):\n",
    "        trues.extend(yseq_true)\n",
    "        preds.extend(yseq_pred)\n",
    "    print_cm(confusion_matrix(trues,preds,labels),labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a Sequence classification model with CRF\n",
      "0.9255103670420659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\env_pracnlp\\lib\\site-packages\\sklearn\\utils\\validation.py:71: FutureWarning: Pass labels=['O', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC', 'B-ORG', 'I-ORG', 'B-PER', 'I-PER'] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O      0.973     0.981     0.977     38323\n",
      "       B-LOC      0.694     0.765     0.728      1668\n",
      "       I-LOC      0.738     0.482     0.584       257\n",
      "      B-MISC      0.648     0.309     0.419       702\n",
      "      I-MISC      0.626     0.505     0.559       216\n",
      "       B-ORG      0.670     0.561     0.611      1661\n",
      "       I-ORG      0.551     0.704     0.618       835\n",
      "       B-PER      0.773     0.766     0.769      1617\n",
      "       I-PER      0.819     0.886     0.851      1156\n",
      "\n",
      "    accuracy                          0.928     46435\n",
      "   macro avg      0.721     0.662     0.679     46435\n",
      "weighted avg      0.926     0.928     0.926     46435\n",
      "\n",
      "\n",
      "\n",
      "                O  B-LOC  I-LOC B-MISC I-MISC  B-ORG  I-ORG  B-PER  I-PER \n",
      "         O  37579    118      3     22     32    193    224     88     64 38323\n",
      "     B-LOC    143   1276      1     36      1     95     14     98      4 1668\n",
      "     I-LOC     32      6    124      1      5      0     52      0     37 257\n",
      "    B-MISC    344     48      1    217      2     56     13     19      2 702\n",
      "    I-MISC     58      1      4      4    109      2     29      0      9 216\n",
      "     B-ORG    265    236      0     48      3    932     20    151      6 1661\n",
      "     I-ORG     76     15     18      2     15     21    588      8     92 835\n",
      "     B-PER     86    138      1      5      3     90     44   1238     12 1617\n",
      "     I-PER     26      1     16      0      4      2     83      0   1024 1156\n",
      "Done with sequence model\n"
     ]
    }
   ],
   "source": [
    "train_path = 'Data/conlldata/train.txt'\n",
    "test_path = 'Data/conlldata/test.txt'\n",
    "conll_train = load__data_conll(train_path)\n",
    "conll_dev = load__data_conll(test_path)\n",
    "\n",
    "print(\"Training a Sequence classification model with CRF\")\n",
    "feats, labels = get_feats_conll(conll_train)\n",
    "devfeats, devlabels = get_feats_conll(conll_dev)\n",
    "train_seq(feats, labels, devfeats, devlabels)\n",
    "print(\"Done with sequence model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.'],\n",
       " ['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conll_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': 'EU',\n",
       "  'prevWord': '<S>',\n",
       "  'prevSecondWord': '<S>',\n",
       "  'nextWord': 'rejects',\n",
       "  'nextNextWord': 'German',\n",
       "  'tag': 'NNP',\n",
       "  'prevTag': '<S>',\n",
       "  'prevSecondTag': '<S>',\n",
       "  'nextTag': 'VBZ',\n",
       "  'nextNextTag': 'JJ'},\n",
       " {'word': 'rejects',\n",
       "  'prevWord': 'EU',\n",
       "  'prevSecondWord': '</S>',\n",
       "  'nextWord': 'German',\n",
       "  'nextNextWord': 'call',\n",
       "  'tag': 'VBZ',\n",
       "  'prevTag': 'NNP',\n",
       "  'prevSecondTag': '</S>',\n",
       "  'nextTag': 'JJ',\n",
       "  'nextNextTag': 'NN'},\n",
       " {'word': 'German',\n",
       "  'prevWord': 'rejects',\n",
       "  'prevSecondWord': 'EU',\n",
       "  'nextWord': 'call',\n",
       "  'nextNextWord': 'to',\n",
       "  'tag': 'JJ',\n",
       "  'prevTag': 'VBZ',\n",
       "  'prevSecondTag': 'NNP',\n",
       "  'nextTag': 'NN',\n",
       "  'nextNextTag': 'TO'},\n",
       " {'word': 'call',\n",
       "  'prevWord': 'German',\n",
       "  'prevSecondWord': 'rejects',\n",
       "  'nextWord': 'to',\n",
       "  'nextNextWord': 'boycott',\n",
       "  'tag': 'NN',\n",
       "  'prevTag': 'JJ',\n",
       "  'prevSecondTag': 'VBZ',\n",
       "  'nextTag': 'TO',\n",
       "  'nextNextTag': 'VB'},\n",
       " {'word': 'to',\n",
       "  'prevWord': 'call',\n",
       "  'prevSecondWord': 'German',\n",
       "  'nextWord': 'boycott',\n",
       "  'nextNextWord': 'British',\n",
       "  'tag': 'TO',\n",
       "  'prevTag': 'NN',\n",
       "  'prevSecondTag': 'JJ',\n",
       "  'nextTag': 'VB',\n",
       "  'nextNextTag': 'JJ'},\n",
       " {'word': 'boycott',\n",
       "  'prevWord': 'to',\n",
       "  'prevSecondWord': 'call',\n",
       "  'nextWord': 'British',\n",
       "  'nextNextWord': 'lamb',\n",
       "  'tag': 'VB',\n",
       "  'prevTag': 'TO',\n",
       "  'prevSecondTag': 'NN',\n",
       "  'nextTag': 'JJ',\n",
       "  'nextNextTag': 'NN'},\n",
       " {'word': 'British',\n",
       "  'prevWord': 'boycott',\n",
       "  'prevSecondWord': 'to',\n",
       "  'nextWord': 'lamb',\n",
       "  'nextNextWord': '.',\n",
       "  'tag': 'JJ',\n",
       "  'prevTag': 'VB',\n",
       "  'prevSecondTag': 'TO',\n",
       "  'nextTag': 'NN',\n",
       "  'nextNextTag': '.'},\n",
       " {'word': 'lamb',\n",
       "  'prevWord': 'British',\n",
       "  'prevSecondWord': 'boycott',\n",
       "  'nextWord': '.',\n",
       "  'nextNextWord': '</S>',\n",
       "  'tag': 'NN',\n",
       "  'prevTag': 'JJ',\n",
       "  'prevSecondTag': 'VB',\n",
       "  'nextTag': '.',\n",
       "  'nextNextTag': '</S>'},\n",
       " {'word': '.',\n",
       "  'prevWord': 'lamb',\n",
       "  'prevSecondWord': 'British',\n",
       "  'nextWord': '</S>',\n",
       "  'nextNextWord': '</S>',\n",
       "  'tag': '.',\n",
       "  'prevTag': 'NN',\n",
       "  'prevSecondTag': 'JJ',\n",
       "  'nextTag': '</S>',\n",
       "  'nextNextTag': '</S>'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In real-world scenarios, using the trained model by itself won’t be sufficient, as the data keeps changing and new entities keep getting added, and there will also be some domain-specific entities or patterns that were not seen in generic training datasets. Hence, most NER systems deployed in real-world scenarios use a combination of ML models, gazetteers, and some pattern matching–based heuristics to improve their performance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER Using an Existing Library (Spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab\n",
    "# https://colab.research.google.com/drive/1z1hHpd8emVHUhth5hnp-fj0UXLsmWlPZ?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER Using Active Learning\n",
    "\n",
    "The best approach to NER when we want customized solutions but don’t want to train everything from scratch is to start with an off-the-shelf product and either augment it with customized heuristics for our problem domain (using tools such as RegexNER or EntityRuler) and/or use active learning using tools like Prodigy.\n",
    "\n",
    "TIPS: Start with a pre-trained NER model and enhance it with heuristics, active learning, or both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab NER BERT\n",
    "# https://colab.research.google.com/drive/1z1hHpd8emVHUhth5hnp-fj0UXLsmWlPZ?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Advice\n",
    "- NER is very sensitive to the format of its input. It’s more accurate with well-formatted plain text than with, say, a PDF document from which plain text needs to be extracted first. One approach is to do custom post-processing of PDFs to extract blobs of text, then run NER on the blobs.\n",
    "- NER is also very sensitive to the accuracy of the prior steps in its processing pipeline: sentence splitting, tokenization, and POS tagging. So, some amount of pre-processing may be necessary before passing a piece of text into an NER model to extract entities.\n",
    "\n",
    "TIPS: If you’re working with documents, such as reports, etc., pre-process them to extract text blobs, then run NER on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
