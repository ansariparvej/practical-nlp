{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Advanced IE Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Temporal Information Extraction\n",
    "\n",
    "Consider an email text: *“Let us meet at 3 p.m. today and decide on what to present at the meeting on Friday.”* Say we’re working on an application to identify and populate calendars with events extracted from such conversations, much like we see in Gmail.\n",
    "\n",
    "To build a similar application, in addition to extracting date and time information (3 pm, today, Friday) from the text, we should also convert the extracted data into some kind of standard form (e.g., mapping the expression “on Friday” to the exact date, based on context, and “today” to today’s date). While extracting date and time information can be done using a collection of handcrafted patterns in the form of regex, or by applying supervised sequence labeling techniques like we did for NER, normalization of extracted date and time into a standard date-time format can be challenging. \n",
    "\n",
    "Together, these tasks are referred to as temporal IE and normalization.\n",
    "\n",
    "- Event Extraction\n",
    "\n",
    "Event extraction is the IE task that deals with identifying and extracting events from text data. It categorized as a supervised learning problem. The ultimate goal is to identify various events over time periods, connect them, and create a temporally ordered event graph.\n",
    "\n",
    "The best way forward is to first start with a rule-based approach based on domain knowledge, then follow it up with weak supervision.\n",
    "\n",
    "![alt text](https://learning.oreilly.com/library/view/practical-natural-language/9781492054047/assets/pnlp_0515.png)\n",
    "\n",
    "- Template Filling\n",
    "\n",
    "Generally, the templates to fill are pre-defined. This is typically modeled as a two-stage, supervised ML problem, similar to relation extraction. \n",
    "\n",
    "The first step involves identifying whether a template is present in a given sentence, and the second step involves identifying slot fillers for that template, with a separate classifier trained for each slot. \n",
    "\n",
    "![alt text](https://learning.oreilly.com/library/view/practical-natural-language/9781492054047/assets/pnlp_0517.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study\n",
    "\n",
    "Problem:\n",
    "- Imagine we work for a large, traditional enterprise. We communicate via email and enterprise messaging platforms like Slack or Yammer. A lot of discussions about meetings happen as part of email threads. There are the three main types of meetings: team meeting, one-on-one meeting, and talk/presentation, plus their associated venues. Say we’re tasked with building a system that automatically finds relevant meetings, books the venue or conference hall, and notifies people.\n",
    "\n",
    "Step 0:\n",
    "-  we might need to restrict what we’re building at the start and solve a more focused problem. \n",
    "\n",
    "Step 1:\n",
    "- we’ll need some amount of labeled data. We can start building labeled data in multiple ways.\n",
    "\n",
    "Step 2:\n",
    "- Let’s say we’re dealing with the following entities and have collected some data with these annotations: Room Name (Meeting Location), Meeting Date, Meeting Time, Meeting Type (derived field), Meeting Invitees. For our first model, we can use a sequence labeling model like conditional random fields (CRFs), which are also used for NER. To classify the type of meeting, we can start with a rule-based classifier based on features such as room size (larger rooms may generally imply larger meetings), number of invitees, etc.\n",
    "\n",
    "Step 3:\n",
    "- Once our system is in deployment, we can start collecting feedback in the form of explicit tagging or more implicit feedback. These may include meeting accept/reject rates and meeting conflict rates on the calendar and for the room. All this information can be used to collect more data so we can apply more sophisticated models.\n",
    "\n",
    "Step 4:\n",
    "- Once we have enough data (5–10K labeled sentences from emails), we can start exploring more powerful language understanding models. If enough compute power is available, we may take advantage of a powerful pre-trained model like BERT and can fine-tune it on the new labeled dataset.\n",
    "\n",
    "Pipeline:\n",
    "![alt text](https://learning.oreilly.com/library/view/practical-natural-language/9781492054047/assets/pnlp_0519.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
