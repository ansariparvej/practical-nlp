{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two types of search engines:\n",
    "- Generic search engines, such as Google and Bing, that crawl the web and aim to cover as much as possible by constantly looking for new webpages\n",
    "- Enterprise search engines, where our search space is restricted to a smaller set of already existing documents within an organization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Typical Enterprise Search Pipeline\n",
    "\n",
    "Steps to build search engine:\n",
    "- Crawling/content acquisition: read data from the location where all the news articles are stored\n",
    "- Text normalization: extracting the main text and discarding additional information, such as tokenizing, lowercasing, etc.\n",
    "- Indexing: vectorize the text, TF-IDF, BERT.\n",
    "\n",
    "\n",
    "What happens when the user types a query?\n",
    "1. Query processing and execution\n",
    "\n",
    "The search query is passed through the text normalization process as above. Once the query is framed, itâ€™s executed, and results are retrieved and ranked according to some notion of relevance. Elasticsearch provide custom scoring functions to modify the ranking of documents retrieved for a given query.\n",
    "\n",
    "2. Feedback and ranking\n",
    "\n",
    "To evaluate search results and make them more relevant to the user, user behavior is recorded and analyzed, and signals such as click action on result and time spent on a result page are used to improve the ranking algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch \n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#elastic search instance has to be running on the machine. Default port is 9200. \n",
    "\n",
    "#Call the Elastic Search instance, and delete any pre-existing index\n",
    "es = Elasticsearch([{'host':'localhost','port':9200}])\n",
    "if es.indices.exists(index=\"myindex\"):\n",
    "    es.indices.delete(index='myindex', ignore=[400, 404]) #Deleting existing index for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n"
     ]
    }
   ],
   "source": [
    "#Build an index from booksummaries dataset. I am using only 500 documents for now.\n",
    "path = \"Data/booksummaries/booksummaries.txt\" #Add your path.\n",
    "count = 1\n",
    "for line in open(path, encoding=\"utf8\"):\n",
    "    fields = line.split(\"\\t\")\n",
    "    doc = {'id' : fields[0],\n",
    "            'title': fields[2],\n",
    "            'author': fields[3],\n",
    "            'summary': fields[6]\n",
    "          }\n",
    "\n",
    "    res = es.index(index=\"myindex\", id=fields[0], body=doc)\n",
    "    count = count+1\n",
    "    if count%100 == 0:\n",
    "        print(\"indexed 100 documents\")\n",
    "#     if count == 501:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your index has 10000 entries\n"
     ]
    }
   ],
   "source": [
    "#Check to see how big is the index\n",
    "res = es.search(index=\"myindex\", body={\"query\": {\"match_all\": {}}})\n",
    "print(\"Your index has %d entries\" % res['hits']['total']['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your search returned 381 results.\n"
     ]
    }
   ],
   "source": [
    "#Try a test query. The query searches \"summary\" field which contains the text\n",
    "#and does a full text query on that field.\n",
    "res = es.search(index=\"myindex\", body={\"query\": {\"match\": {\"summary\": \"animal\"}}})\n",
    "print(\"Your search returned %d results.\" % res['hits']['total']['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Animal Farm\n",
      " Old Major, the old boar on the Manor Farm, calls the animals on the farm for a meeting, where he co\n"
     ]
    }
   ],
   "source": [
    "#Printing the title field and summary field's first 100 characters for 2nd result\n",
    "print(res[\"hits\"][\"hits\"][2][\"_source\"][\"title\"])\n",
    "print(res[\"hits\"][\"hits\"][2][\"_source\"][\"summary\"][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your search query: wind\n",
      "Your search returned 235 results:\n",
      "At the Back of the North Wind\n",
      " The book tells the story of a young boy named Diamond. He is a very sweet little boy who makes joy \n",
      "trying to sleep, Diamond repeatedly plugs up a hole in the loft (also his bedroom) wall to stop the wind from blowing in. However, he soon finds out that this is stopping the North Wind from seeing th\n",
      "Sword Quest\n",
      " There is war in the kingdom of birds, which was started by the prehistoric birds known as the archa\n",
      "o escape and lays an egg. When the egg hatches to reveal a fully feathered hatchling, she names him Wind-Voice. Meanwhile, the four-winged creature, named Yin Soul, is stuck between the world of the l\n",
      "Clash Of The Sky Galleons\n",
      " The story is set aboard the Sky pirate ship The Galerider. Wind Jackal wants revenge against his pr\n",
      "\n",
      "The Wind Boy\n",
      " The novel is about a boy named Kay and a girl named Gentian who are foreign children and somewhat o\n",
      " mirrors their own. In the Clear Land, they each purchase a pair of Clear Land sandals and meet The Wind Boy, a handsome boy with purple wings. They learn that The Wind Boy once owned a horrible mask,\n",
      "The Wind Done Gone\n",
      " The plot of Gone with the Wind revolves around a pampered Southern woman named Scarlett O'Hara, who\n",
      "\n",
      "A Wind Named Amnesia\n",
      " The Apocalypse didn't come with a bang, but with a whimper. Silently, the amnesia wind swept away a\n",
      "\n",
      "Matari\n",
      " The story is set in 18th century Japan, and features a conflict between four very different charact\n",
      "conflict between four very different characters - Oboko (nb, Obaku is a form of Zen), a poet of the wind and Buddhist monk; Izzi, court poet and extrovert; Lord Arishi, samurai and lord of the realm; \n",
      "Dragonsblood\n",
      " Occasional chapters of Dragonsblood are set soon after the end of the First Pass of the Red Star, n\n",
      "First Pass of the Red Star, nearly 450 years before most of the action. There (or then) the elderly Wind Blossom, a geneticist and daughter of the legendary Kitti Ping, is bemoaning the gradual loss o\n",
      "Young Men and Fire\n",
      " Norman Maclean and Laird Robinson, in an attempt to forensically analyze the Mann Gulch Fire, broug\n",
      "forest fire investigators, Maclean and Laird came to new conclusions on the fire's events: that the wind went in the opposite direction than was originally thought possible, and once the fire got star\n",
      "Pinball, 1973\n",
      " The plot centers on the narrator's brief but intense obsession with pinball, his life as a freelanc\n",
      "are present. Wells, which are mentioned often in Murakami's novels and play a prominent role in The Wind-Up Bird Chronicle, occur several times in Pinball. There is also a brief discussion of the abus\n",
      "Enter your search query: STOP\n"
     ]
    }
   ],
   "source": [
    "#match query considers both exact matches, and fuzzy matches and works as a OR query. \n",
    "#match_phrase looks for exact matches.\n",
    "while True:\n",
    "    query = input(\"Enter your search query: \")\n",
    "    if query == \"STOP\":\n",
    "        break\n",
    "    res = es.search(index=\"myindex\", body={\"query\": {\"match_phrase\": {\"summary\": query}}})\n",
    "    print(\"Your search returned %d results:\" % res['hits']['total']['value'])\n",
    "    for hit in res[\"hits\"][\"hits\"]:\n",
    "        print(hit[\"_source\"][\"title\"])\n",
    "        #to get a snippet 100 characters before and after the match\n",
    "        loc = hit[\"_source\"][\"summary\"].lower().index(query)\n",
    "        print(hit[\"_source\"][\"summary\"][:100])\n",
    "        print(hit[\"_source\"][\"summary\"][loc-100:loc+100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
